{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "STS.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lyuiixp/CodeStates_Section1_Project/blob/main/siamese/STS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Textual Similarity for Korean\n",
        "\n"
      ],
      "metadata": {
        "id": "3qfGz4Pa-Whu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "6R8hyvUu-1sK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Sw7ilyV-KU8",
        "outputId": "1e51b995-587e-415d-e7aa-9a74fa282d57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 71.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentence_transformers"
      ],
      "metadata": {
        "id": "aNJmsci54p08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb2f7638-1bc2-40fd-a60a-7192168b9915"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.19.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 24.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.11.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.12.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=d6ad6ebf2008430016e8697d29856bd00262ec61b86537329f7fcac3fdce26a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.0 sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader,  RandomSampler, SequentialSampler, random_split\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
        "from transformers import BertTokenizer\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "kpKhz3Xi_A2j"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJA6wul9_SI3",
        "outputId": "3f54b8b6-e7a6-4e4d-fbeb-b675d4483c40"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seed\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "3UzKrJFze4Le"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmKwlaCj_o-U",
        "outputId": "e672d3b2-8950-4da2-ec93-12a182f5020d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdAJVTDRcerk",
        "outputId": "65da1edd-9947-4bc7-abfd-ab0ea3c26ed9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/snaiws/NLP_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96O7yDjQ4GrO",
        "outputId": "bd4d46f2-f4e9-4352-8abe-e09d2f029b21"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP_project'...\n",
            "remote: Enumerating objects: 250, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 250 (delta 65), reused 38 (delta 38), pack-reused 160\u001b[K\n",
            "Receiving objects: 100% (250/250), 6.39 MiB | 11.36 MiB/s, done.\n",
            "Resolving deltas: 100% (124/124), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/NLP_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3YRxEPN4H06",
        "outputId": "1a344bc4-ba97-481b-d075-76c8c7d2bfce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ARGUMENT and Model"
      ],
      "metadata": {
        "id": "Iz2aZrF5Wg6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir('/content/drive/MyDrive/NLP_project/CustomModels'))"
      ],
      "metadata": {
        "id": "0NoUvfiIbibP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc195d88-6802-4778-b57a-82394b99d94b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BERT_baseline.py', 'BERT_seq.py']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, models\n",
        "import torch.nn as nn\n",
        "\n",
        "class sroberta(nn.Module):\n",
        "    def __init__(self, hidden_size: int, n_label: int, freeze_base: bool = False):\n",
        "        super(sroberta, self).__init__()\n",
        "        embedding_model = models.Transformer(\n",
        "            model_name_or_path = 'klue/roberta-base', \n",
        "            max_seq_length = 256,\n",
        "            do_lower_case = True\n",
        "        )\n",
        "        pooling_model = models.Pooling(\n",
        "            embedding_model.get_word_embedding_dimension(),\n",
        "            pooling_mode_mean_tokens=True,\n",
        "            pooling_mode_cls_token=False,\n",
        "            pooling_mode_max_tokens=False,\n",
        "        )\n",
        "        self.sroberta = SentenceTransformer(modules=[embedding_model, pooling_model])\n",
        "        \n",
        "\n",
        "        dropout_rate = 0.1\n",
        "        linear_layer_hidden_size = 6\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "        nn.Linear(hidden_size, linear_layer_hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(linear_layer_hidden_size, n_label)\n",
        "        )\n",
        "\n",
        "    \n",
        "\n",
        "    def forward(self):\n",
        "      # , input_ids=None, attention_mask=None, token_type_ids=None\n",
        "        outputs = self.sroberta(\n",
        "            #input_ids,\n",
        "            #attention_mask=attention_mask,\n",
        "            #token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "        last_hidden_states = outputs[0] # last hidden states (batch_size, sequence_len, hidden_size)\n",
        "        cls_token_last_hidden_states = last_hidden_states[:,0,:] # (batch_size, first_token, hidden_size)\n",
        "\n",
        "        logits = self.classifier(cls_token_last_hidden_states)\n",
        "\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "tkH--LTg8op7"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# argument setting\n",
        "train_batch_size = 58\n",
        "eval_batch_size = 64\n",
        "epochs=25\n",
        "patience=2\n",
        "\n",
        "loss_fct = nn.CrossEntropyLoss()\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"klue/roberta-small\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"klue/roberta-base\")\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"klue/roberta-large\")\n",
        "customModel = sroberta(hidden_size=768, n_label=6)\n",
        "customOptimizer = AdamW(\n",
        "    customModel.parameters(), # update 대상 파라미터를 입력\n",
        "    lr=2.335281794951567e-05,\n",
        "    eps=1e-8\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRem4PpiMzAo",
        "outputId": "e3d4420c-fea6-4f38-da24-9f71e7c85381"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import losses\n",
        "# Use CosineSimilarityLoss\n",
        "train_loss = losses.CosineSimilarityLoss(model=customModel)\n",
        "\n",
        "# warmup steps\n",
        "warmup_steps = math.ceil(len(sts_train_examples) * sts_num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
        "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
        "\n",
        "# Training\n",
        "customModel.fit(\n",
        "    train_objectives=[(train_dataloader, train_loss)],\n",
        "    evaluator=dev_evaluator,\n",
        "    epochs=sts_num_epochs,\n",
        "    evaluation_steps=int(len(train_dataloader)*0.1),\n",
        "    warmup_steps=warmup_steps,\n",
        "    output_path=sts_model_save_path\n",
        ")"
      ],
      "metadata": {
        "id": "I_Whd6Cp81_I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "c7b7ac37-ebd3-4081-96b2-50124663c814"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-be92df003d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Use CosineSimilarityLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCosineSimilarityLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# warmup steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Given data"
      ],
      "metadata": {
        "id": "yKpuYKgO_iBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 내 json 불러오기\n",
        "df_train0 = pd.read_json('./data/klue-sts-v1.1_train.json')\n",
        "df_test0 = pd.read_json('./data/klue-sts-v1.1_dev.json')"
      ],
      "metadata": {
        "id": "XEnQbro_AFC3"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape\n",
        "df_train0.shape, df_test0.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4t-v3-EAdKr",
        "outputId": "926bd0d8-7954-4a04-9297-7f871f447c31"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11668, 6), (519, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collected data"
      ],
      "metadata": {
        "id": "OkjYey9KAmwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bhuXo-IiMf1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### target balence"
      ],
      "metadata": {
        "id": "mcNuklZsRJ3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0['labels'].map(lambda x: x['real-label']).hist(bins=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "_oZuc4_sDF5B",
        "outputId": "13e96e41-f4e3-4a6c-8124-cee9ef165fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f72a3c870d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPUklEQVR4nO3db4xcV33G8e9DQtvIaZug0JVlWzUvLKS0UUO6SpBA1aaowQmoSaUKEaXg0FTui0QCNVJr+iYtCMlvQlsiGtUFi0RNsSIBsgURqeVmhSI1EJuGmCTQWOAotkIs6mBYqFqZ/vpir+lg73p3Z+fP7pzvRxrNzLl37pzf7s4zZ869dzZVhSSpDa8bdwckSaNj6EtSQwx9SWqIoS9JDTH0Jakhl467Axdz1VVX1datW/t+/I9//GM2bNgwuA6tA63V3Fq9YM2tWE3NR44c+X5VvXGhZWs69Ldu3crhw4f7fvzs7CwzMzOD69A60FrNrdUL1tyK1dSc5KXFljm9I0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDVnTZ+Su1tGTZ7hz15cuaD+++11j6I0kjZ8jfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGLBn6SbYkeSLJ80meS/LBrv0NSQ4mebG7vrJrT5JPJDmW5Nkk1/Vsa0e3/otJdgyvLEnSQpYz0j8L3FtVVwNvBe5OcjWwCzhUVduAQ919gJuBbd1lJ/AgzL9JAPcBNwDXA/ede6OQJI3GkqFfVa9U1de72z8CXgA2AbcCD3WrPQTc1t2+FXi45j0FXJFkI/BO4GBVna6q14CDwPaBViNJuqhLV7Jykq3AW4CvAlNV9Uq36HvAVHd7E/Byz8NOdG2LtZ//HDuZ/4TA1NQUs7OzK+niz5m6DO695uwF7avZ5lo3Nzc30fWdr7V6wZpbMayalx36SS4HPgd8qKp+mORny6qqktQgOlRVe4A9ANPT0zUzM9P3th54ZD/3H72wxON39L/NtW52dpbV/MzWm9bqBWtuxbBqXtbRO0lez3zgP1JVn++aX+2mbeiuT3XtJ4EtPQ/f3LUt1i5JGpHlHL0T4NPAC1X18Z5FB4BzR+DsAPb3tL+/O4rnrcCZbhroceCmJFd2O3Bv6tokSSOynOmdtwHvA44meaZr+0tgN/BokruAl4D3dMseA24BjgE/AT4AUFWnk3wUeLpb7yNVdXogVUiSlmXJ0K+qJ4EssvgdC6xfwN2LbGsvsHclHZQkDY5n5EpSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIUuGfpK9SU4l+WZP218lOZnkme5yS8+yDyc5luTbSd7Z0769azuWZNfgS5EkLWU5I/3PANsXaP+bqrq2uzwGkORq4L3Ab3SP+fsklyS5BPgkcDNwNXB7t64kaYQuXWqFqvpKkq3L3N6twL6q+m/gu0mOAdd3y45V1XcAkuzr1n1+xT2WJPVtydC/iHuSvB84DNxbVa8Bm4CnetY50bUBvHxe+w0LbTTJTmAnwNTUFLOzs313cOoyuPeasxe0r2aba93c3NxE13e+1uoFa27FsGruN/QfBD4KVHd9P/DHg+hQVe0B9gBMT0/XzMxM39t64JH93H/0whKP39H/Nte62dlZVvMzW29aqxesuRXDqrmv0K+qV8/dTvKPwBe7uyeBLT2rbu7auEi7JGlE+jpkM8nGnrt/AJw7sucA8N4kv5jkTcA24GvA08C2JG9K8gvM7+w90H+3JUn9WHKkn+SzwAxwVZITwH3ATJJrmZ/eOQ78KUBVPZfkUeZ30J4F7q6qn3bbuQd4HLgE2FtVzw28GknSRS3n6J3bF2j+9EXW/xjwsQXaHwMeW1HvJEkD5Rm5ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDVky9JPsTXIqyTd72t6Q5GCSF7vrK7v2JPlEkmNJnk1yXc9jdnTrv5hkx3DKkSRdzHJG+p8Btp/Xtgs4VFXbgEPdfYCbgW3dZSfwIMy/SQD3ATcA1wP3nXujkCSNzpKhX1VfAU6f13wr8FB3+yHgtp72h2veU8AVSTYC7wQOVtXpqnoNOMiFbySSpCG7tM/HTVXVK93t7wFT3e1NwMs9653o2hZrv0CSncx/SmBqaorZ2dk+uwhTl8G915y9oH0121zr5ubmJrq+87VWL1hzK4ZVc7+h/zNVVUlqEJ3ptrcH2AMwPT1dMzMzfW/rgUf2c//RC0s8fkf/21zrZmdnWc3PbL1prV6w5lYMq+Z+j955tZu2obs+1bWfBLb0rLe5a1usXZI0Qv2G/gHg3BE4O4D9Pe3v747ieStwppsGehy4KcmV3Q7cm7o2SdIILTm9k+SzwAxwVZITzB+Fsxt4NMldwEvAe7rVHwNuAY4BPwE+AFBVp5N8FHi6W+8jVXX+zmFJ0pAtGfpVdfsii96xwLoF3L3IdvYCe1fUO0nSQHlGriQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5Iasup/oiJJw3b05Bnu3PWlC9qP737XGHqzvjnSl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUkCb/XeLWBf7tGviv1yRNPkf6ktSQJkf6ksbLT9vjY+hLWrd881g5p3ckqSGrCv0kx5McTfJMksNd2xuSHEzyYnd9ZdeeJJ9IcizJs0muG0QBkqTlG8RI/8aquraqprv7u4BDVbUNONTdB7gZ2NZddgIPDuC5JUkrMIzpnVuBh7rbDwG39bQ/XPOeAq5IsnEIzy9JWkSqqv8HJ98FXgMK+Ieq2pPkB1V1Rbc8wGtVdUWSLwK7q+rJbtkh4C+q6vB529zJ/CcBpqamfnvfvn199+/U6TO8+l/LX/+aTb/a93OtFXNzc1x++eXj7sbItFYvTEbNR0+eWbB9sdegr+WVufHGG4/0zL78nNUevfP2qjqZ5NeAg0m+1buwqirJit5VqmoPsAdgenq6ZmZm+u7cA4/s5/6jyy/x+B39P9daMTs7y2p+ZutNa/XCZNR852JH3SzyGvS1PDirmt6pqpPd9SngC8D1wKvnpm2661Pd6ieBLT0P39y1SZJGpO+RfpINwOuq6kfd7ZuAjwAHgB3A7u56f/eQA8A9SfYBNwBnquqV1XRe0mh5XPz6t5rpnSngC/PT9lwK/HNVfTnJ08CjSe4CXgLe063/GHALcAz4CfCBVTy3JKkPfYd+VX0H+K0F2v8TeMcC7QXc3e/zSZJWzzNyJakhfveOpFVzrn/9cKQvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kN8YxcSUOz2Jm6Gh9H+pLUEEf6kiaO3wW0OEN/CPyDk9ami003Lfb6nLTXs9M7ktQQR/o9Ju0dXZLOZ+hLDXOg0x5DX1pnjp48w50rOBTSAFcv5/QlqSGO9JdhXB+B/egtjU4rJ5IZ+hNmsY/+vlFIAkN/VVY6MnDkLmncnNOXpIY40pd0gVbmt1tk6EsTzgBXL0O/Ee5PkATO6UtSUxzpa1272NmpfoqRLmToayCcPuqfPzuNkqG/Brij7f9NQgBOQg1a2nr9PRv6WtCg/qDX0wtjpX0d1Ml5mixr/W/eHbmS1BBH+ppYa33EJY2Doa/mOM2icVgrgxCndySpIY70GzeunZGOtqV5i70WPrN9w1Ceb+Shn2Q78HfAJcCnqmr3qPsgrYRvUJokI53eSXIJ8EngZuBq4PYkV4+yD5LUslHP6V8PHKuq71TV/wD7gFtH3AdJalaqanRPlvwhsL2q/qS7/z7ghqq6p2edncDO7u6bgW+v4imvAr6/isevR63V3Fq9YM2tWE3Nv15Vb1xowZrbkVtVe4A9g9hWksNVNT2Iba0XrdXcWr1gza0YVs2jnt45CWzpub+5a5MkjcCoQ/9pYFuSNyX5BeC9wIER90GSmjXS6Z2qOpvkHuBx5g/Z3FtVzw3xKQcyTbTOtFZza/WCNbdiKDWPdEeuJGm8/BoGSWqIoS9JDZnI0E+yPcm3kxxLsmvc/Rm2JHuTnEryzXH3ZVSSbEnyRJLnkzyX5IPj7tOwJfmlJF9L8o2u5r8ed59GIcklSf49yRfH3ZdRSXI8ydEkzyQ5PNBtT9qcfvdVD/8B/B5wgvkjhm6vqufH2rEhSvI7wBzwcFX95rj7MwpJNgIbq+rrSX4ZOALcNuG/5wAbqmouyeuBJ4EPVtVTY+7aUCX5M2Aa+JWqeve4+zMKSY4D01U18BPSJnGk39xXPVTVV4DT4+7HKFXVK1X19e72j4AXgE3j7dVw1by57u7ru8tkjdrOk2Qz8C7gU+Puy6SYxNDfBLzcc/8EEx4GrUuyFXgL8NXx9mT4uqmOZ4BTwMGqmvSa/xb4c+B/x92RESvgX5Ic6b6aZmAmMfTVkCSXA58DPlRVPxx3f4atqn5aVdcyfzb79UkmdjovybuBU1V1ZNx9GYO3V9V1zH8j8d3dFO5ATGLo+1UPjejmtT8HPFJVnx93f0apqn4APAFsH3dfhuhtwO9389v7gN9N8k/j7dJoVNXJ7voU8AXmp60HYhJD3696aEC3U/PTwAtV9fFx92cUkrwxyRXd7cuYP1jhW+Pt1fBU1YeranNVbWX+dfyvVfVHY+7W0CXZ0B2cQJINwE3AwI7Mm7jQr6qzwLmvengBeHTIX/Uwdkk+C/wb8OYkJ5LcNe4+jcDbgPcxP/p7prvcMu5ODdlG4IkkzzI/uDlYVc0cxtiQKeDJJN8AvgZ8qaq+PKiNT9whm5KkxU3cSF+StDhDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXk/wD0nqP87hZi3gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0['labels'].map(lambda x: x['binary-label']).value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "KQrM6E1I_9Qe",
        "outputId": "44838e5a-614d-4107-e8df-dff08a100535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f72a3241fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### duplicates"
      ],
      "metadata": {
        "id": "IHjeDztYBMBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 중복\n",
        "df_train0[df_train0.duplicated(['sentence1','sentence2'],keep=False)==True]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 893
        },
        "id": "v7AhrCRiAi9b",
        "outputId": "c7d4088b-5282-401b-a2cf-4a7753ea8fef"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          guid      source  \\\n",
              "1514   klue-sts-v1_train_01514  policy-rtt   \n",
              "1661   klue-sts-v1_train_01661  airbnb-rtt   \n",
              "1715   klue-sts-v1_train_01715  airbnb-rtt   \n",
              "3872   klue-sts-v1_train_03872  policy-rtt   \n",
              "5139   klue-sts-v1_train_05139  policy-rtt   \n",
              "5292   klue-sts-v1_train_05292  policy-rtt   \n",
              "7045   klue-sts-v1_train_07045  policy-rtt   \n",
              "10908  klue-sts-v1_train_10908  policy-rtt   \n",
              "10939  klue-sts-v1_train_10939  policy-rtt   \n",
              "11112  klue-sts-v1_train_11112  policy-rtt   \n",
              "\n",
              "                                               sentence1  \\\n",
              "1514   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "1661                     택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.   \n",
              "1715                     택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.   \n",
              "3872   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "5139   지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "5292   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "7045   지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "10908  지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "10939  지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...   \n",
              "11112  제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...   \n",
              "\n",
              "                                               sentence2  \\\n",
              "1514   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "1661                택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.   \n",
              "1715                택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.   \n",
              "3872   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "5139   지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "5292   제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "7045   지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "10908  지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "10939  지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...   \n",
              "11112  제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...   \n",
              "\n",
              "                                                  labels  \\\n",
              "1514   {'label': 4.7, 'real-label': 4.714285714285714...   \n",
              "1661   {'label': 4.7, 'real-label': 4.666666666666667...   \n",
              "1715   {'label': 4.7, 'real-label': 4.666666666666667...   \n",
              "3872   {'label': 4.9, 'real-label': 4.857142857142857...   \n",
              "5139   {'label': 4.6, 'real-label': 4.571428571428571...   \n",
              "5292   {'label': 4.7, 'real-label': 4.714285714285714...   \n",
              "7045   {'label': 4.0, 'real-label': 4.0, 'binary-labe...   \n",
              "10908  {'label': 4.0, 'real-label': 4.0, 'binary-labe...   \n",
              "10939  {'label': 4.6, 'real-label': 4.571428571428571...   \n",
              "11112  {'label': 4.9, 'real-label': 4.857142857142857...   \n",
              "\n",
              "                                             annotations  \n",
              "1514   {'agreement': '0:0:0:0:2:5', 'annotators': ['0...  \n",
              "1661   {'agreement': '0:0:0:0:2:4', 'annotators': ['1...  \n",
              "1715   {'agreement': '0:0:0:0:2:4', 'annotators': ['1...  \n",
              "3872   {'agreement': '0:0:0:0:1:6', 'annotators': ['1...  \n",
              "5139   {'agreement': '0:0:0:0:3:4', 'annotators': ['0...  \n",
              "5292   {'agreement': '0:0:0:0:2:5', 'annotators': ['0...  \n",
              "7045   {'agreement': '0:0:0:1:5:1', 'annotators': ['1...  \n",
              "10908  {'agreement': '0:0:0:1:5:1', 'annotators': ['1...  \n",
              "10939  {'agreement': '0:0:0:0:3:4', 'annotators': ['0...  \n",
              "11112  {'agreement': '0:0:0:0:1:6', 'annotators': ['1...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff403333-3f52-4b17-a453-949ebbf4da29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guid</th>\n",
              "      <th>source</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>labels</th>\n",
              "      <th>annotations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>klue-sts-v1_train_01514</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.714285714285714...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:5', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1661</th>\n",
              "      <td>klue-sts-v1_train_01661</td>\n",
              "      <td>airbnb-rtt</td>\n",
              "      <td>택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.</td>\n",
              "      <td>택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.666666666666667...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:4', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1715</th>\n",
              "      <td>klue-sts-v1_train_01715</td>\n",
              "      <td>airbnb-rtt</td>\n",
              "      <td>택시타고 공항갔을 때 20유로로 15분내에 도착했었어요.</td>\n",
              "      <td>택시를 타고 공항에 갔을 때, 15분만에 20유로에 도착했습니다.</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.666666666666667...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:4', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3872</th>\n",
              "      <td>klue-sts-v1_train_03872</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.9, 'real-label': 4.857142857142857...</td>\n",
              "      <td>{'agreement': '0:0:0:0:1:6', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5139</th>\n",
              "      <td>klue-sts-v1_train_05139</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.6, 'real-label': 4.571428571428571...</td>\n",
              "      <td>{'agreement': '0:0:0:0:3:4', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5292</th>\n",
              "      <td>klue-sts-v1_train_05292</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.714285714285714...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:5', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7045</th>\n",
              "      <td>klue-sts-v1_train_07045</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.0, 'real-label': 4.0, 'binary-labe...</td>\n",
              "      <td>{'agreement': '0:0:0:1:5:1', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10908</th>\n",
              "      <td>klue-sts-v1_train_10908</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.0, 'real-label': 4.0, 'binary-labe...</td>\n",
              "      <td>{'agreement': '0:0:0:1:5:1', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10939</th>\n",
              "      <td>klue-sts-v1_train_10939</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>지난달 하루 평균 수출액이 전년대비 5.6% 증가한 가운데 자동차는 2017년 11...</td>\n",
              "      <td>지난 달 평균 일일 수출액이 전년 동월대비 5.6% 증가하면서, 자동차의 수출은 2...</td>\n",
              "      <td>{'label': 4.6, 'real-label': 4.571428571428571...</td>\n",
              "      <td>{'agreement': '0:0:0:0:3:4', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11112</th>\n",
              "      <td>klue-sts-v1_train_11112</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사는 ...</td>\n",
              "      <td>제2차 전략회의에서 대전, 경기, 강원, 전남, 제주, 경남 등 6개 시·도지사가 ...</td>\n",
              "      <td>{'label': 4.9, 'real-label': 4.857142857142857...</td>\n",
              "      <td>{'agreement': '0:0:0:0:1:6', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff403333-3f52-4b17-a453-949ebbf4da29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff403333-3f52-4b17-a453-949ebbf4da29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff403333-3f52-4b17-a453-949ebbf4da29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test0[df_test0.duplicated(['sentence1','sentence2'],keep=False)==True]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "_yuCC-wKCnPr",
        "outputId": "65193cfa-344c-4343-8b7a-d7112392fb21"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [guid, source, sentence1, sentence2, labels, annotations]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63d4a448-43ee-4013-a5a2-8de6c244fa0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guid</th>\n",
              "      <th>source</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>labels</th>\n",
              "      <th>annotations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63d4a448-43ee-4013-a5a2-8de6c244fa0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63d4a448-43ee-4013-a5a2-8de6c244fa0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63d4a448-43ee-4013-a5a2-8de6c244fa0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([df_train0.drop_duplicates(['sentence1','sentence2']),df_test0]).duplicated(['sentence1','sentence2']).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKhRexrZC4aE",
        "outputId": "5bac3f92-ea65-4652-f493-b7476717559d"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0.isna().sum().sum()+df_test0.isna().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Y9-rovDxnE",
        "outputId": "8af79e8b-68f9-47f2-bb4a-dbbbbd2ee04e"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocess"
      ],
      "metadata": {
        "id": "ySxzpHXJQR1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "2L3Qg_QqFKpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_st(text):\n",
        "  text = re.sub(r\"[^ㄱ-힣0-9\\s]\",\"\",text)\n",
        "  return text\n",
        "\n",
        "def base_preprocess(train, test):\n",
        "    train = train.drop_duplicates(['sentence1','sentence2']).reset_index(drop=True)\n",
        "    s1 = train['sentence1'].map(lambda x: check_st(x))\n",
        "    s2 = train['sentence2'].map(lambda x: check_st(x))\n",
        "    real = train['labels'].map(lambda x: int(x['real-label']))\n",
        "    binary = train['labels'].map(lambda x: int(x['binary-label']))\n",
        "    train = pd.concat([s1,s2,real,binary],axis=1)\n",
        "    train.columns = ['sentence1','sentence2','real','binary']\n",
        "    train['sentence'] = train.apply(lambda x: [x['sentence1'], x['sentence2']],axis=1)\n",
        "\n",
        "    s1 = test['sentence1'].map(lambda x: check_st(x))\n",
        "    s2 = test['sentence2'].map(lambda x: check_st(x))\n",
        "    real = test['labels'].map(lambda x: int(x['real-label']))\n",
        "    binary = test['labels'].map(lambda x: int(x['binary-label']))\n",
        "    test = pd.concat([s1,s2,real,binary],axis=1)\n",
        "    test.columns = ['sentence1','sentence2','real','binary']\n",
        "    test['sentence'] = test.apply(lambda x: [x['sentence1'], x['sentence2']],axis=1)\n",
        " \n",
        "    return train, test"
      ],
      "metadata": {
        "id": "jVwblZvZQXGI"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = base_preprocess(df_train0,df_test0)"
      ],
      "metadata": {
        "id": "u7hYDHWGCm0C"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.sentence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4-KhSCLZh-F",
        "outputId": "4bafca5e-304c-42b7-e0b7-488c21190533"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다',\n",
              " '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다']"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fu8-BMqCC93p",
        "outputId": "0eb59a00-8a9e-4c19-fe99-216a6530419f"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           sentence1  \\\n",
              "0                    숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다   \n",
              "1         위반행위 조사 등을 거부방해기피한 자는 500만원 이하 과태료 부과 대상이다   \n",
              "2             회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘   \n",
              "3  긴급 고용안정지원금은 지역고용대응 등 특별지원금 지자체별 소상공인 지원사업 취업성공...   \n",
              "4                          호스트의 답장이 늦으나 개선될 것으로 보입니다   \n",
              "\n",
              "                                   sentence2  real  binary  \\\n",
              "0  숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다     3       1   \n",
              "1       시민들 스스로 자발적인 예방 노력을 한 것은 아산 뿐만이 아니었다     0       0   \n",
              "2                 사람들이 주로 네이버 메일을 쓰는 이유를 알려줘     0       0   \n",
              "3    고용보험이 1차 고용안전망이라면 국민취업지원제도는 2차 고용안전망입니다     0       0   \n",
              "4                  호스트 응답이 늦었지만 개선될 것으로 보입니다     4       1   \n",
              "\n",
              "                                            sentence  \n",
              "0  [숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다, 숙박시설의 위치는 쉽게...  \n",
              "1  [위반행위 조사 등을 거부방해기피한 자는 500만원 이하 과태료 부과 대상이다, 시...  \n",
              "2  [회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘, 사람들이 ...  \n",
              "3  [긴급 고용안정지원금은 지역고용대응 등 특별지원금 지자체별 소상공인 지원사업 취업성...  \n",
              "4  [호스트의 답장이 늦으나 개선될 것으로 보입니다, 호스트 응답이 늦었지만 개선될 것...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a152d661-1527-4540-9820-60db21e02d26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>real</th>\n",
              "      <th>binary</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다</td>\n",
              "      <td>숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>[숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다, 숙박시설의 위치는 쉽게...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>위반행위 조사 등을 거부방해기피한 자는 500만원 이하 과태료 부과 대상이다</td>\n",
              "      <td>시민들 스스로 자발적인 예방 노력을 한 것은 아산 뿐만이 아니었다</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[위반행위 조사 등을 거부방해기피한 자는 500만원 이하 과태료 부과 대상이다, 시...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘</td>\n",
              "      <td>사람들이 주로 네이버 메일을 쓰는 이유를 알려줘</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘, 사람들이 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>긴급 고용안정지원금은 지역고용대응 등 특별지원금 지자체별 소상공인 지원사업 취업성공...</td>\n",
              "      <td>고용보험이 1차 고용안전망이라면 국민취업지원제도는 2차 고용안전망입니다</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[긴급 고용안정지원금은 지역고용대응 등 특별지원금 지자체별 소상공인 지원사업 취업성...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>호스트의 답장이 늦으나 개선될 것으로 보입니다</td>\n",
              "      <td>호스트 응답이 늦었지만 개선될 것으로 보입니다</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>[호스트의 답장이 늦으나 개선될 것으로 보입니다, 호스트 응답이 늦었지만 개선될 것...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a152d661-1527-4540-9820-60db21e02d26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a152d661-1527-4540-9820-60db21e02d26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a152d661-1527-4540-9820-60db21e02d26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentation"
      ],
      "metadata": {
        "id": "IAIZB6y0kIyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nMHTC1mtkLKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token length"
      ],
      "metadata": {
        "id": "kzwHEv74DBou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tknz(text):\n",
        "    x = tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True, # max_length를 넘는 문장은 이 후 토큰을 제거함\n",
        "            max_length=512,\n",
        "            return_tensors='pt' # 토크나이즈된 결과 값을 텐서 형태로 반환\n",
        "        )\n",
        "    return x"
      ],
      "metadata": {
        "id": "Sb9Ns_a6_w-J"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['sentence1'].map(lambda x: tknz(x).input_ids.shape[1]).value_counts().sort_index().plot(kind='bar',figsize=(10,5))"
      ],
      "metadata": {
        "id": "mZHw4B4Ls3et",
        "outputId": "babdef5a-3731-4eec-a189-9a7965bb0407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbc73eca350>"
            ]
          },
          "metadata": {},
          "execution_count": 158
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['sentence2'].map(lambda x: tknz(x).input_ids.shape[1]).value_counts().sort_index().plot(kind='bar',figsize=(10,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "qVQ_9azlPoBy",
        "outputId": "3c9f90fb-9e32-4d7a-dc0b-27ee5881760e"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbc74065c50>"
            ]
          },
          "metadata": {},
          "execution_count": 159
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['sentence'].map(lambda x: tknz(x).input_ids.shape[1]).value_counts().sort_index().plot(kind='bar',figsize=(20,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "Ss_2IIv8C09d",
        "outputId": "9e540be6-679f-4e63-efc4-dc9c56884ace"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 17 at dim 1 (got 23)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-160-666411d240c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtknz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4159\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4160\u001b[0m         \"\"\"\n\u001b[0;32m-> 4161\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4162\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[1;32m   4163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-160-666411d240c9>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtknz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-157-ade715a7e4e4>\u001b[0m in \u001b[0;36mtknz\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# max_length를 넘는 문장은 이 후 토큰을 제거함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m \u001b[0;31m# 토크나이즈된 결과 값을 텐서 형태로 반환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         )\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2492\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2494\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2495\u001b[0m             )\n\u001b[1;32m   2496\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2683\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2685\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2686\u001b[0m         )\n\u001b[1;32m   2687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         )\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_batch_prepare_for_model\u001b[0;34m(self, batch_ids_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_length, verbose)\u001b[0m\n\u001b[1;32m    812\u001b[0m         )\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    722\u001b[0m                     )\n\u001b[1;32m    723\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 724\u001b[0;31m                     \u001b[0;34m\"Unable to create tensor, you should probably activate truncation and/or padding \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m                     \u001b[0;34m\"with 'padding=True' 'truncation=True' to have batched tensors with the same length.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                 )\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "DUsE3dGzTBpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    - input_data: list of string\n",
        "    - target_data: list of int\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_data:list, target_data:list) -> None:\n",
        "        self.X = input_data\n",
        "        self.Y = target_data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.Y[index]"
      ],
      "metadata": {
        "id": "nrxcSuANS3ua"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.sentence.to_list()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufhaTBtVXTp6",
        "outputId": "f2e2f60f-c4da-48e8-e6b9-3cb2c8292150"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다',\n",
              " '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다']"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(df_train.sentence.to_list(), df_train.real.to_list())\n",
        "test_dataset = CustomDataset(df_test.sentence.to_list(), df_test.real.to_list())"
      ],
      "metadata": {
        "id": "qHRSCsPX_XiU"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxFolynJYHDD",
        "outputId": "aa0219ec-6990-4f52-bfa5-d1357d5dbc7e"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다',\n",
              "  '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다'],\n",
              " 3)"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Data"
      ],
      "metadata": {
        "id": "_xnq7qO8VeXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_sample = df_train.shape[0] # train 전체 길이\n",
        "n_train = int(n_sample*0.9)\n",
        "n_valid = n_sample-n_train\n",
        "train_dataset, valid_dataset = random_split(train_dataset, [n_train, n_valid],generator=torch.Generator().manual_seed(seed))"
      ],
      "metadata": {
        "id": "YhDSTrpoVhuM"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train Dataset len: {len(train_dataset)}\")\n",
        "print(f\"Valid Dataset len: {len(valid_dataset)}\")\n",
        "print(f\"Test Dataset len: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3VF0hHy_qbg",
        "outputId": "fde350b4-9f78-442c-a201-1e74a2b45ea3"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset len: 10494\n",
            "Valid Dataset len: 1167\n",
            "Test Dataset len: 519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plan"
      ],
      "metadata": {
        "id": "PUZIdwDiW8Wc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loader"
      ],
      "metadata": {
        "id": "gxJnvrXwWENj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom collate_fn \n",
        "def BERT_base_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    한 배치 내 문장들을 tokenizing 한 후 텐서로 변환함. \n",
        "    이때, dynamic padding (즉, 같은 배치 내 토큰의 개수가 동일할 수 있도록, 부족한 문장에 [PAD] 토큰을 추가하는 작업)을 적용\n",
        "    \n",
        "    한 배치 내 레이블(target)은 텐서화 함.\n",
        "    \n",
        "    - batch: list of tuples (input_data(string), target_data(int))\n",
        "    \"\"\"\n",
        "    input_list, target_list = [], []\n",
        "\n",
        "    for _input, _target in batch:\n",
        "        input_list.append(_input)\n",
        "        target_list.append(_target)\n",
        "    \n",
        "    tensorized_input = tokenizer(\n",
        "        input_list,\n",
        "        add_special_tokens=True,\n",
        "        padding=\"longest\", # 배치내 가장 긴 문장을 기준으로 부족한 문장은 [PAD] 토큰을 추가\n",
        "        truncation=True, # max_length를 넘는 문장은 이 후 토큰을 제거함\n",
        "        max_length=512,\n",
        "        return_tensors='pt' # 토크나이즈된 결과 값을 텐서 형태로 반환\n",
        "    )\n",
        "    \n",
        "    tensorized_label = torch.tensor(target_list)\n",
        "    \n",
        "    return tensorized_input, tensorized_label"
      ],
      "metadata": {
        "id": "45DCZ7_5WGs4"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_data_loader(train_dataset,valid_dataset,test_dataset):\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size = train_batch_size,\n",
        "        sampler = RandomSampler(train_dataset,generator=torch.Generator().manual_seed(seed)),\n",
        "        collate_fn = BERT_base_collate_fn\n",
        "    )\n",
        "\n",
        "    valid_dataloader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size = eval_batch_size,\n",
        "        sampler = SequentialSampler(valid_dataset),\n",
        "        collate_fn = BERT_base_collate_fn\n",
        "    )\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size = eval_batch_size,\n",
        "        sampler = SequentialSampler(test_dataset),\n",
        "        collate_fn = BERT_base_collate_fn\n",
        "    )\n",
        "    print(f\"Train dataloader # steps: {len(train_dataloader)}\")\n",
        "    print(f\"Valid dataloader # steps: {len(valid_dataloader)}\")\n",
        "    print(f\"Test dataloader # steps: {len(test_dataloader)}\")\n",
        "    return train_dataloader, valid_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "afNNT7crFH28"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, valid_dataloader, test_dataloader = init_data_loader(train_dataset,valid_dataset,test_dataset)"
      ],
      "metadata": {
        "id": "1hnqiWsHaiaW",
        "outputId": "657fb4eb-2ccf-4f76-c5af-e27bd5023914",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader # steps: 181\n",
            "Valid dataloader # steps: 19\n",
            "Test dataloader # steps: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializer"
      ],
      "metadata": {
        "id": "fb4K-Oo8Fc7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initializer(model, optimizer, train_dataloader, epochs=2):\n",
        "    \"\"\"\n",
        "    모델, 옵티마이저, 스케쥴러 초기화\n",
        "    \"\"\"\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    print(f\"Total train steps with {epochs} epochs: {total_steps}\")\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps = 0, # 여기서는 warmup을 사용하지 않는다.\n",
        "        num_training_steps = total_steps\n",
        "    )\n",
        "\n",
        "    return model, optimizer, scheduler"
      ],
      "metadata": {
        "id": "i4omKhdSQfpJ"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Early stopping"
      ],
      "metadata": {
        "id": "NwgtRhD4FhSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
        "    def __init__(self, patience=1, verbose=False, delta=0, path='checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: 'checkpoint.pt'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = os.path.abspath(os.curdir)\n",
        "\n",
        "    def __call__(self, val_loss, model, optimizer, scheduler, epoch):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model, optimizer, scheduler, epoch, val_loss)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model, optimizer, scheduler, epoch, val_loss)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, scheduler, epoch, loss):\n",
        "        file_name = f'{self.path}/model.ckpt.best'\n",
        "        \n",
        "        torch.save(\n",
        "            {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'loss' : loss\n",
        "            }, \n",
        "            file_name\n",
        "        )\n",
        "      \n",
        "        print(f\"Saving epoch {epoch} checkpoint at {file_name}\")"
      ],
      "metadata": {
        "id": "xjTgaMgaJLIo"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "X9A_WhPZIIW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataloader, valid_dataloader=None, epochs=1):\n",
        "    # early_stopping object의 초기화\n",
        "    early_stopping = EarlyStopping(patience = patience, verbose = True)\n",
        "    \n",
        "    # train_dataloaer 학습을 epochs만큼 반복\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "        \n",
        "        # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n",
        "        total_loss, batch_loss, batch_count = 0,0,0\n",
        "    \n",
        "        # model을 train 모드로 설정 & device 할당\n",
        "        model.train()\n",
        "        model.to(device)\n",
        "        \n",
        "        # data iterator를 돌면서 하나씩 학습\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_count+=1\n",
        "            \n",
        "            # tensor 연산 전, 각 tensor에 device 할당\n",
        "            batch = tuple(item.to(device) for item in batch)\n",
        "        \n",
        "            batch_input, batch_label = batch\n",
        "        \n",
        "            # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n",
        "            model.zero_grad()\n",
        "        \n",
        "            # forward\n",
        "            logits = model(**batch_input)\n",
        "            # loss\n",
        "            loss = loss_fct(logits, batch_label)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "        \n",
        "            # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n",
        "            loss.backward()\n",
        "            \n",
        "            # gradient clipping 적용 \n",
        "            clip_grad_norm_(model.parameters(), 1.0)\n",
        "            \n",
        "            # optimizer & scheduler 업데이트\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # 배치 10개씩 처리할 때마다 평균 loss와 lr를 출력\n",
        "            if (step % 10 == 0 and step != 0):\n",
        "                learning_rate = optimizer.param_groups[0]['lr']\n",
        "                print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
        "\n",
        "                # reset \n",
        "                batch_loss, batch_count = 0,0\n",
        "        \n",
        "        print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "        print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n",
        "        \n",
        "        if valid_dataloader is not None:\n",
        "            print(f\"*****Epoch {epoch} Valid Start*****\")\n",
        "            valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "            print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f} Valid Acc : {valid_acc:.2f}\")\n",
        "            print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n",
        "\n",
        "        # early_stopping는 validation loss가 감소하였는지 확인이 필요하며,\n",
        "        #  만약 감소하였을경우 현제 모델을 checkpoint로 만든다.\n",
        "        early_stopping(valid_loss, model, optimizer, scheduler, epoch)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "            \n",
        "            \n",
        "    print(\"Train Completed. End Program.\")"
      ],
      "metadata": {
        "id": "kK09khnhJQfo"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validate"
      ],
      "metadata": {
        "id": "fBx_gbpYFmSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, valid_dataloader):\n",
        "   \n",
        "    # 모델을 evaluate 모드로 설정 & device 할당\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    \n",
        "    total_loss, total_acc= 0,0\n",
        "        \n",
        "    for step, batch in enumerate(valid_dataloader):\n",
        "        \n",
        "        # tensor 연산 전, 각 tensor에 device 할당\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "        batch_input, batch_label = batch\n",
        "            \n",
        "        # gradient 계산하지 않음\n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            \n",
        "        # loss\n",
        "        loss = loss_fct(logits, batch_label)\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # accuracy\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1).flatten()\n",
        "        acc = (preds == batch_label).cpu().numpy().mean()\n",
        "        total_acc+=acc\n",
        "    \n",
        "    total_loss = total_loss/(step+1)\n",
        "    total_acc = total_acc/(step+1)*100\n",
        "\n",
        "    return total_loss, total_acc\n",
        "    "
      ],
      "metadata": {
        "id": "C21fot6EJNSL"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "XuwLP7lzepZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reset gpu cache\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ZepTYxNV_QPi"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "y, M, d, h, m, s, w, yd, isdst = time.gmtime()\n",
        "current_time = f'{y}.{M}.{d} {h+9}:{m}:{s}'\n",
        "print(current_time)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "newModel = copy.deepcopy(customModel)\n",
        "newOptimizer = copy.deepcopy(customOptimizer)\n",
        "train_dataloader, valid_dataloader, test_dataloader = init_data_loader(train_dataset,valid_dataset,test_dataset)\n",
        "model, optimizer, scheduler = initializer(newModel, newOptimizer, train_dataloader, epochs)\n",
        "#train_model(model, train_dataloader, valid_dataloader, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QLtohXGJUJF",
        "outputId": "319f627d-a028-4f92-b621-14a26001c0c5"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022.6.2 13:31:10\n",
            "Train dataloader # steps: 181\n",
            "Valid dataloader # steps: 19\n",
            "Test dataloader # steps: 9\n",
            "Total train steps with 25 epochs: 4525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_dataloader, valid_dataloader, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "mb03xlSGd1wk",
        "outputId": "76e3239e-0269-498c-e080-7a00f607ad31"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****Epoch 1 Train Start*****\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-232-d0e21cbda71b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-207-5abf40c99495>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, valid_dataloader, epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;31m# loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-222-af15d98e778d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;31m# attention_mask=None, token_type_ids=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmodel_save_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"output/training_klue_sts_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'klue/roberta-base'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d_%H-%M-%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         outputs = self.sroberta(model_save_path\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;31m#input_ids,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m#attention_mask=attention_mask,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;34m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mtrans_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'token_type_ids'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mtrans_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "GFiQGULKrxfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load checkpoint"
      ],
      "metadata": {
        "id": "4aim45otF4si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(f'./model.ckpt.best')"
      ],
      "metadata": {
        "id": "I4StQ5rCRPJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSy2twvbRSHd",
        "outputId": "db020b6a-3b55-4d12-9407-77d9178008b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss'])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=1\n",
        "model, optimizer, scheduler = initializer(customModel, customOptimizer, train_dataloader, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOuSODA6RSQ9",
        "outputId": "33ac309d-957e-484a-ccf5-aa47906e51ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train steps with 1 epochs: 181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(checkpoint[\"model_state_dict\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAoxlaI_RSTb",
        "outputId": "eaa4b097-c279-4182-b199-784f267c3672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### predict and evaluate"
      ],
      "metadata": {
        "id": "w1uKfufLF8kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, test_dataloader):\n",
        "    \"\"\"\n",
        "    test_dataloader의 label별 확률값과 실제 label 값을 반환\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "        print(f\"{step}/{len(test_dataloader)}\")\n",
        "        \n",
        "        batch_input, batch_label = batch\n",
        "        \n",
        "        batch_input = batch_input.to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            all_logits.append(logits)\n",
        "        all_labels.extend(batch_label)\n",
        "\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    return probs, all_labels\n"
      ],
      "metadata": {
        "id": "UhtXfy8kJvMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs, labels = predict(model, test_dataloader)"
      ],
      "metadata": {
        "id": "NQAuNkxRRdxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4946026-f8af-4f81-aa29-6d74b7a477bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/9\n",
            "1/9\n",
            "2/9\n",
            "3/9\n",
            "4/9\n",
            "5/9\n",
            "6/9\n",
            "7/9\n",
            "8/9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = list(map(np.argmax,probs))"
      ],
      "metadata": {
        "id": "MjSIuizoaVg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from scipy.stats import pearsonr\n",
        "def evaluate(pred, test):\n",
        "    if len(set(pred))==2:\n",
        "        pred_binary = pred\n",
        "        test_binary_label = test\n",
        "    else:\n",
        "        pred_binary = list(map(lambda x: 1 if x>=3 else 0, pred))\n",
        "        test_binary_label = list(map(lambda x: 1 if x>=3 else 0, test))\n",
        "    print(f'acc : {accuracy_score(test_binary_label, pred_binary)}')\n",
        "    print(f'f1 : {f1_score(test_binary_label, pred_binary)}')\n",
        "    print(f'pearson : {pearsonr(test, pred)}')\n",
        "    return f1_score(test_binary_label, pred_binary)\n",
        "    "
      ],
      "metadata": {
        "id": "r_CM_p_SzS3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(pred, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv_HfFaARi6o",
        "outputId": "3cf38912-4204-44a6-f002-5ed813390826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc : 0.8246628131021194\n",
            "f1 : 0.8239845261121855\n",
            "pearson : (0.6864423052926801, 1.5053604699392324e-73)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8239845261121855"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save outputs"
      ],
      "metadata": {
        "id": "UwfT52-LGDrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.DataFrame(labels,columns=['pred_real_label'])\n",
        "filename = input()\n",
        "output.to_csv(f'{filename}.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWOiLVeOGFay",
        "outputId": "2b8a02fb-6c85-4b9e-a165-66c01fce97a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT_seq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "G7e_OlKR4qni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model weights"
      ],
      "metadata": {
        "id": "ODz2YVO45-MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Bert_baseline(hidden_size=768, n_label=6)"
      ],
      "metadata": {
        "id": "nNiDZphx5FXK",
        "outputId": "0ee120c1-cc92-4a8d-ce9b-4f7772b7bb97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "probs, labels = predict(model, test_dataloader)"
      ],
      "metadata": {
        "id": "rG_D-WBV5kMU",
        "outputId": "4effe6e2-a9ea-46d8-ecf4-c442a3939ed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/9\n",
            "1/9\n",
            "2/9\n",
            "3/9\n",
            "4/9\n",
            "5/9\n",
            "6/9\n",
            "7/9\n",
            "8/9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = list(map(np.argmax,probs))\n",
        "evaluate(pred, labels)"
      ],
      "metadata": {
        "id": "vzg0kIpZ5z66",
        "outputId": "4961f688-3c8b-4f89-94fc-ac026e7fe063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc : 0.7533718689788054\n",
            "f1 : 0.7697841726618705\n",
            "pearson : (0.7789983354145806, 7.071859924703616e-107)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning"
      ],
      "metadata": {
        "id": "ZDS8IJNaVyB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "C91sdB_P6Cym",
        "outputId": "109b7df0-6550-45c1-9a2e-5b14c40a79c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.8 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 61.7 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 40.5 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.8 MB/s \n",
            "\u001b[?25hCollecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.2.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=7f541bfeef2de537dec7387efa5126d8ecd12a3669ea4434672bb8cc0cf69a0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.8.0 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.0 pbr-5.9.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna"
      ],
      "metadata": {
        "id": "YrDmE0uyMjvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optuna_train(model, optimizer):\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "        batch_input, batch_label = batch\n",
        "        model.zero_grad()\n",
        "        logits = model(**batch_input)\n",
        "        loss = loss_fct(logits, batch_label)\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "QJT780IPACjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):  # `trial` is an object passed by Optuna.\n",
        "    train_batch_size = trial.suggest_int(\"train_batch_size\",24,64)\n",
        "    lr = trial.suggest_float(\"lr\",1e-6,1e-3,log=True)\n",
        "\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size = train_batch_size,\n",
        "        sampler = RandomSampler(train_dataset),\n",
        "        collate_fn = BERT_base_collate_fn\n",
        "        )\n",
        "    model = copy.deepcopy(customModel)\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), lr = lr\n",
        "        )\n",
        "    val_list = []\n",
        "    for epoch in range(4):\n",
        "        optuna_train(model,optimizer)\n",
        "        valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "        print(f'val_los : {valid_loss}')\n",
        "        trial.report(valid_loss, step = epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "        val_list.append(valid_loss)\n",
        "    return min(val_list)"
      ],
      "metadata": {
        "id": "jksNuvvL6C03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reset gpu cache\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "v_L_9OT9mivx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(\n",
        "    direction='minimize',\n",
        "    sampler=optuna.samplers.TPESampler(seed=seed),\n",
        "    pruner=optuna.pruners.HyperbandPruner(\n",
        "        min_resource=1, \n",
        "        max_resource=4, \n",
        "        reduction_factor=3\n",
        "    ))\n",
        "study.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "id": "KuKNaaDS6C56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "27503d89-054d-400f-e8a6-f897065146bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 04:53:35,969]\u001b[0m A new study created in memory with name: no-name-d03c4b3a-4a0c-4487-a2f7-e7fc0059dcee\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_los : 1.846707444441946\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-250-8b558256efde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mreduction_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     ))\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-248-a090945ac0ee>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mval_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moptuna_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'val_los : {valid_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-243-b942e528c784>\u001b[0m in \u001b[0;36moptuna_train\u001b[0;34m(model, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Minimum objective value: ' + str(study.best_value))\n",
        "print('Best parameter: ' + str(study.best_params))"
      ],
      "metadata": {
        "id": "QarUZ2Vm6C3c",
        "outputId": "b87790be-fd26-448b-f0c2-a81f18dc638a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-d33a5a21f9e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Minimum objective value: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best parameter: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36mbest_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mbest_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mbest_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36mbest_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m             )\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_study_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/storages/_in_memory.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mbest_trial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_studies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_trial_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No trials are completed yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_studies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirections\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
          ]
        }
      ]
    }
  ]
}